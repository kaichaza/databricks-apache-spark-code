{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1da81e3-d6ff-4f71-8312-85318a95834b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parallel RAG Notebook\n",
    "This notebook uses **GPT-5** and **FAISS** to perform parallel retrieval and generation on Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5489a853-7010-4f70-bfc2-bdf426c22798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai faiss-cpu pandas\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b63d587-e6c4-4bf3-b25c-34476b3d44fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Retrieve API Key from Secrets\n",
    "os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(\"solution-accelerator-cicd\", \"openai_api\")\n",
    "\n",
    "client = OpenAI()\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "LLM_MODEL = \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa91f99-3fff-4103-a158-457d60971e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Local Documents\n",
    "doc_dir = \"/documents\"\n",
    "if not os.path.exists(doc_dir):\n",
    "    os.makedirs(doc_dir)\n",
    "\n",
    "agents = {\n",
    "    \"jett.txt\": \"Jett is a duelist. Abilities: Tailwind, Cloudburst.\",\n",
    "    \"sage.txt\": \"Sage is a sentinel. Abilities: Healing Orb, Resurrection.\",\n",
    "    \"sova.txt\": \"Sova is an initiator. Abilities: Recon Bolt, Owl Drone.\",\n",
    "    \"phoenix.txt\": \"Phoenix is a duelist. Abilities: Curveball, Blaze.\",\n",
    "    \"viper.txt\": \"Viper is a controller. Abilities: Toxic Screen, Poison Cloud.\"\n",
    "}\n",
    "\n",
    "for filename, content in agents.items():\n",
    "    with open(os.path.join(doc_dir, filename), \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2285965d-a0ef-41b0-90a2-84c5e0c1068d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Indexing with FAISS\n",
    "documents = [open(os.path.join(doc_dir, f)).read() for f in os.listdir(doc_dir)]\n",
    "\n",
    "def get_emb(texts):\n",
    "    res = client.embeddings.create(input=texts, model=EMBEDDING_MODEL)\n",
    "    return np.array([d.embedding for d in res.data]).astype('float32')\n",
    "\n",
    "embeddings = get_emb(documents)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a8f089-7650-4925-82da-965f4f2fd79d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NEW: Broadcast variables to all cluster nodes\n",
    "broadcast_docs = sc.broadcast(documents)\n",
    "broadcast_index = sc.broadcast(index)\n",
    "\n",
    "# Ensure workers have access to the API key in their environment\n",
    "os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(\"solution-accelerator-cicd\", \"openai_api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5bd05c3-000b-409f-82df-f171a0ee02f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Updated Parallel RAG via Spark\n",
    "queries = [\"Jett abilities?\", \"Sage role?\", \"Sova tools?\", \"Phoenix flash?\", \"Viper gas?\"]\n",
    "df_q = spark.createDataFrame(pd.DataFrame(queries, columns=[\"question\"]))\n",
    "\n",
    "def ask_gpt_worker(q):\n",
    "    # Initialize a NEW client inside the worker to avoid pickling errors\n",
    "    worker_client = OpenAI()\n",
    "    \n",
    "    # Access the broadcasted variables\n",
    "    local_index = broadcast_index.value\n",
    "    local_docs = broadcast_docs.value\n",
    "    \n",
    "    # 1. Retrieval (using broadcasted index)\n",
    "    res_emb = worker_client.embeddings.create(input=[q], model=EMBEDDING_MODEL)\n",
    "    vec = np.array([res_emb.data[0].embedding]).astype('float32')\n",
    "    \n",
    "    _, idx = local_index.search(vec, 1)\n",
    "    ctx = local_docs[idx[0][0]]\n",
    "    \n",
    "    # 2. Generation (using GPT-5)\n",
    "    ans = worker_client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Use context to answer concisely.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {ctx}\\nQuestion: {q}\"}\n",
    "        ]\n",
    "    )\n",
    "    return ans.choices[0].message.content\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def parallel_rag(s: pd.Series) -> pd.Series:\n",
    "    # This runs on cluster executors in parallel\n",
    "    return s.apply(ask_gpt_worker)\n",
    "\n",
    "# Display results\n",
    "display(df_q.withColumn(\"gpt_5_answer\", parallel_rag(df_q[\"question\"])))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "databricks_rag_2026",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
