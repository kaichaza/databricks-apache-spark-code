{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valorant Parallel RAG Notebook\n",
    "This notebook uses **GPT-5** and **FAISS** to perform parallel retrieval and generation on Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Retrieve API Key from Secrets\n",
    "os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(\"solution-accelerator-cicd\", \"openai_api\")\n",
    "\n",
    "client = OpenAI()\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "LLM_MODEL = \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Local Documents\n",
    "doc_dir = \"/documents\"\n",
    "if not os.path.exists(doc_dir):\n",
    "    os.makedirs(doc_dir)\n",
    "\n",
    "agents = {\n",
    "    \"jett.txt\": \"Jett is a duelist. Abilities: Tailwind, Cloudburst.\",\n",
    "    \"sage.txt\": \"Sage is a sentinel. Abilities: Healing Orb, Resurrection.\",\n",
    "    \"sova.txt\": \"Sova is an initiator. Abilities: Recon Bolt, Owl Drone.\",\n",
    "    \"phoenix.txt\": \"Phoenix is a duelist. Abilities: Curveball, Blaze.\",\n",
    "    \"viper.txt\": \"Viper is a controller. Abilities: Toxic Screen, Poison Cloud.\"\n",
    "}\n",
    "\n",
    "for filename, content in agents.items():\n",
    "    with open(os.path.join(doc_dir, filename), \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing with FAISS\n",
    "documents = [open(os.path.join(doc_dir, f)).read() for f in os.listdir(doc_dir)]\n",
    "\n",
    "def get_emb(texts):\n",
    "    res = client.embeddings.create(input=texts, model=EMBEDDING_MODEL)\n",
    "    return np.array([d.embedding for d in res.data]).astype('float32')\n",
    "\n",
    "embeddings = get_emb(documents)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel RAG via Spark\n",
    "queries = [\"Jett abilities?\", \"Sage role?\", \"Sova tools?\", \"Phoenix flash?\", \"Viper gas?\"]\n",
    "df_q = spark.createDataFrame(pd.DataFrame(queries, columns=[\"question\"]))\n",
    "\n",
    "def ask_gpt(q):\n",
    "    vec = get_emb([q])\n",
    "    _, idx = index.search(vec, 1)\n",
    "    ctx = documents[idx[0][0]]\n",
    "    \n",
    "    ans = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Use context to answer concisely.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {ctx}\\nQuestion: {q}\"}\n",
    "        ]\n",
    "    )\n",
    "    return ans.choices[0].message.content\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def parallel_rag(s: pd.Series) -> pd.Series:\n",
    "    return s.apply(ask_gpt)\n",
    "\n",
    "display(df_q.withColumn(\"gpt_5_answer\", parallel_rag(df_q[\"question\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}